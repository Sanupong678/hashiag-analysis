"""
Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô database
"""
import sys
import os
from pathlib import Path
import asyncio

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ encoding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows terminal
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ‡πÄ‡∏û‡∏¥‡πà‡∏° path ‡∏Ç‡∏≠‡∏á backend ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô sys.path
backend_path = Path(__file__).parent.parent
sys.path.insert(0, str(backend_path))

from database.db_config import db
from processors.batch_data_processor import batch_processor
from utils.stock_list_fetcher import stock_list_fetcher
from datetime import datetime

def fetch_all_news(force_refresh=False, batch_size=50):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô database
    
    Args:
        force_refresh: ‡∏ñ‡πâ‡∏≤ True ‡∏à‡∏∞‡∏î‡∏∂‡∏á‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
        batch_size: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏∏‡πâ‡∏ô‡∏ï‡πà‡∏≠ batch
    """
    try:
        print("\n" + "="*60)
        print("üì∞ ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô Database")
        print("="*60)
        
        if db is None:
            print("‚ùå Database not available")
            return
        
        # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡∏à‡∏≤‡∏Å database
        symbols = []
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å db.stock_tickers
        if hasattr(db, 'stock_tickers') and db.stock_tickers is not None:
            ticker_docs = db.stock_tickers.find({"isActive": True})
            symbols = [doc["ticker"] for doc in ticker_docs if doc.get("ticker")]
            print(f"\n‚úÖ Found {len(symbols)} stocks from db.stock_tickers")
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô stock_tickers ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å stock_list_fetcher
        if not symbols:
            print(f"\nüìã Fetching from stock_list_fetcher...")
            all_symbols = stock_list_fetcher.get_all_valid_tickers(force_refresh=False)
            symbols = list(all_symbols) if all_symbols else []
            print(f"‚úÖ Found {len(symbols)} stocks from stock_list_fetcher")
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å db.stocks (‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)
        if not symbols and hasattr(db, 'stocks') and db.stocks is not None:
            stock_docs = db.stocks.find({}, {"symbol": 1})
            symbols = [doc["symbol"] for doc in stock_docs if doc.get("symbol")]
            symbols = list(set(symbols))  # Remove duplicates
            print(f"‚úÖ Found {len(symbols)} stocks from db.stocks")
        
        if not symbols:
            print("\n‚ùå No stock symbols found in database")
            print("   Please ensure stock tickers are loaded in database first")
            return
        
        print(f"\nüìä Total stocks to process: {len(symbols):,}")
        print(f"   Batch size: {batch_size}")
        print(f"   Force refresh: {force_refresh}")
        
        from utils.post_normalizer import get_collection_name
        
        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° (‡πÉ‡∏ä‡πâ collection post_yahoo)
        collection_name = get_collection_name('yahoo')
        total_news_before = 0
        if hasattr(db, collection_name) and getattr(db, collection_name) is not None:
            post_collection = getattr(db, collection_name)
            total_news_before = post_collection.count_documents({})
            print(f"   üì∞ Current news in database: {total_news_before:,}")
        
        # ‡∏ñ‡πâ‡∏≤ force_refresh = False ‡πÉ‡∏´‡πâ skip ‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
        if not force_refresh:
            print(f"\n‚è≠Ô∏è  Skipping stocks that already have news...")
            symbols_to_process = []
            skipped_count = 0
            for symbol in symbols:
                symbol_upper = symbol.upper()
                if hasattr(db, collection_name) and getattr(db, collection_name) is not None:
                    post_collection = getattr(db, collection_name)
                    news_count = post_collection.count_documents({"symbol": symbol_upper})
                    if news_count == 0:
                        symbols_to_process.append(symbol)
                    else:
                        skipped_count += 1
            symbols = symbols_to_process
            print(f"   ‚úÖ {len(symbols):,} stocks need news fetching")
            print(f"   ‚è≠Ô∏è  {skipped_count:,} stocks skipped (already have news)")
        
        if not symbols:
            print("\n‚úÖ All stocks already have news in database!")
            return
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ batch processor
        batch_processor.days_back = 7
        
        print(f"\nüöÄ Starting news fetching...")
        print("="*60)
        
        # ‡∏£‡∏±‡∏ô batch processing (async)
        start_time = datetime.now()
        results = asyncio.run(
            batch_processor.process_all_stocks_async(symbols, batch_size=batch_size)
        )
        end_time = datetime.now()
        elapsed = (end_time - start_time).total_seconds()
        
        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à (‡πÉ‡∏ä‡πâ collection post_yahoo)
        total_news_after = 0
        if hasattr(db, collection_name) and getattr(db, collection_name) is not None:
            post_collection = getattr(db, collection_name)
            total_news_after = post_collection.count_documents({})
        
        new_news = total_news_after - total_news_before
        
        print("\n" + "="*70)
        print("üéâ" * 35)
        print("="*70)
        print("‚úÖ NEWS FETCHING COMPLETED! ‚úÖ")
        print("="*70)
        print(f"üìä Stocks processed: {len(results):,}/{len(symbols):,}")
        print(f"üì∞ News articles fetched: {new_news:,} new articles")
        print(f"üìö Total news in database: {total_news_after:,} articles")
        print(f"‚è±Ô∏è  Time elapsed: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)")
        if len(results) > 0:
            print(f"‚ö° Average: {elapsed/len(results):.2f} seconds per stock")
        print("="*70)
        print("üéâ" * 35)
        print("="*70 + "\n")
        
        # üîä ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        try:
            import sys
            if sys.platform == 'win32':
                import winsound
                winsound.Beep(1000, 500)
                winsound.Beep(1500, 500)
            elif sys.platform == 'darwin':
                import subprocess
                subprocess.run(['say', 'News fetching completed!'])
            elif sys.platform.startswith('linux'):
                print('\a')
        except Exception:
            pass
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Fetch news for all stocks in database')
    parser.add_argument('--force-refresh', action='store_true', 
                       help='Fetch news even if stocks already have news')
    parser.add_argument('--batch-size', type=int, default=50,
                       help='Number of stocks per batch (default: 50)')
    
    args = parser.parse_args()
    
    fetch_all_news(force_refresh=args.force_refresh, batch_size=args.batch_size)

